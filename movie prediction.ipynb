{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview the dataset\n",
    "df = pd.read_csv('IMDb Movies India.csv', encoding='ISO-8859-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get information about the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get summary statistics of the datset\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['Rating'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Genre'].fillna('Unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract numeric values from 'Duration' and convert to integers\n",
    "df['Duration'] = df['Duration'].str.extract(r'(\\d+)').astype(float)\n",
    "\n",
    "# Impute missing values in 'Duration' with the median\n",
    "df['Duration'].fillna(df['Duration'].median(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['Actor 1', 'Actor 2', 'Actor 3'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Year'] = df['Year'].str.extract(r'(\\d+)').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Votes'] = df['Votes'].str.extract(r'(\\d+)').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview the clean dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the dark_background style\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "# Define the numerical columns you want to check for outliers\n",
    "numerical_columns = ['Year', 'Votes']\n",
    "\n",
    "# Create box plots before removing outliers\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.suptitle('Box Plots Before Removing Outliers', fontsize=16)\n",
    "\n",
    "for i, column in enumerate(numerical_columns, 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    df.boxplot(column=[column])\n",
    "    plt.title(f'{column}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate z-scores for numerical columns\n",
    "z_scores = pd.DataFrame()\n",
    "for column in numerical_columns:\n",
    "    z_scores[column] = (df[column] - df[column].mean()) / df[column].std()\n",
    "\n",
    "# Set a z-score threshold to identify outliers (e.g., 2 or -2 for a 95% confidence interval)\n",
    "z_score_threshold = 2\n",
    "\n",
    "# Identify outliers based on z-scores\n",
    "outliers = z_scores[(z_scores.abs() > z_score_threshold).any(axis=1)]\n",
    "\n",
    "# Display the number of rows with outliers before removal\n",
    "print(\"Number of rows with outliers before removal:\", len(outliers))\n",
    "\n",
    "# Remove outliers and create a new DataFrame (df_cleaned)\n",
    "df = df[~((z_scores.abs() > z_score_threshold).any(axis=1))]\n",
    "\n",
    "# Create box plots after removing outliers\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.suptitle('Box Plots After Removing Outliers', fontsize=16)\n",
    "\n",
    "for i, column in enumerate(numerical_columns, 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    df.boxplot(column=[column])\n",
    "    plt.title(f'{column}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the number of rows after removing outliers\n",
    "print(\"Number of rows after removing outliers:\", len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rating analysis\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=df, x='Rating', bins=30, kde=True)\n",
    "plt.title('Distribution of Movie Ratings')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votes Analysis\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=df, x='Votes', bins=30, kde=True)\n",
    "plt.title('Distribution of Votes')\n",
    "plt.xlabel('Number of Votes')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Count the number of movies directed by each director\n",
    "director_counts = df['Director'].value_counts()\n",
    "\n",
    "# Select the top 10 directors with the most movies directed\n",
    "top_10_directors = director_counts.head(10)\n",
    "\n",
    "# Create a bar plot to visualize the top 10 directors with the most movies directed\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(top_10_directors.index, top_10_directors.values),\n",
    "plt.title('Top 10 Directors with the Most Movies Directed')\n",
    "plt.xlabel('Director')\n",
    "plt.ylabel('Number of Movies Directed')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of movies in which each actor starred\n",
    "actor_counts = df[['Actor 1', 'Actor 2', 'Actor 3']].stack().value_counts()\n",
    "\n",
    "# Select the top 10 actors with the most movie appearances\n",
    "top_10_actors = actor_counts.head(10)\n",
    "\n",
    "# Create a bar plot to visualize the top 10 actors with the most movie appearances\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(top_10_actors.index, top_10_actors.values,  color='skyblue')\n",
    "plt.title('Top 10 Actors with the Most Movie Appearances')\n",
    "plt.xlabel('Actor')\n",
    "plt.ylabel('Number of Movie Appearances')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by director and find the maximum rating within each group\n",
    "directors_max_rating = df.groupby('Director')['Rating'].max()\n",
    "\n",
    "# Sort the directors by their highest rating in descending order and select the top 10\n",
    "top_10_directors = directors_max_rating.sort_values(ascending=False).head(10)\n",
    "\n",
    "# Create a bar plot to visualize the top 10 directors with the highest-rated movies\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(top_10_directors.index, top_10_directors.values)\n",
    "plt.title('Top 10 Directors with the Highest-Rated Movies')\n",
    "plt.xlabel('Director')\n",
    "plt.ylabel('Maximum Rating')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by genre and calculate the mean rating for each genre\n",
    "genre_mean_ratings = df.groupby('Genre')['Rating'].mean()\n",
    "\n",
    "# Sort the genres by mean rating in descending order and select the top 10\n",
    "top_10_genres = genre_mean_ratings.sort_values(ascending=False).head(10)\n",
    "\n",
    "# Create a bar plot to visualize the top 10 highly rated genres\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(top_10_genres.index, top_10_genres.values, color='skyblue')\n",
    "plt.title('Top 10 Highly Rated Movie Genres')\n",
    "plt.xlabel('Genre')\n",
    "plt.ylabel('Mean Rating')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for the most recent 20 years\n",
    "recent_years = df[df['Year'] >= (max(df['Year']) - 19)]\n",
    "\n",
    "# Calculate the average rating per year\n",
    "average_ratings = recent_years.groupby('Year')['Rating'].mean().reset_index()\n",
    "\n",
    "# Sort the DataFrame by average rating in descending order and select the top 10 years\n",
    "top_10_years = average_ratings.nlargest(10, 'Rating')\n",
    "\n",
    "# Plot the top 10 years and their average ratings\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(top_10_years['Year'], top_10_years['Rating'])\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Average Rating')\n",
    "plt.title('Top 10 Years with Highest Average Ratings (Recent 20 Years)')\n",
    "plt.xticks(top_10_years['Year'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['Duration'], df['Rating'], alpha=0.5, color='blue')\n",
    "plt.xlabel('Duration (minutes)')\n",
    "plt.ylabel('Rating')\n",
    "plt.title('Duration vs Rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix\n",
    "corr_matrix = df.corr(numeric_only=True)\n",
    "\n",
    "\n",
    "# Create a heatmap to visualize correlations\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the numerical variables for the pair plot\n",
    "numerical_columns = df.select_dtypes(include=['number'])\n",
    "\n",
    "# Create a pair plot for the numerical variables\n",
    "sns.pairplot(numerical_columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Rating', axis=1)\n",
    "y = df['Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.corr(numeric_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Specify the categorical columns to be one-hot encoded\n",
    "categorical_columns = ['Name', 'Genre', 'Director',\n",
    "       'Actor 1', 'Actor 2', 'Actor 3']\n",
    "\n",
    "# Initialize the OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Fit and transform the categorical columns\n",
    "X_categorical_encoded = ohe.fit_transform(X[categorical_columns])\n",
    "\n",
    "# Retrieve feature names for the encoded columns\n",
    "feature_names = []\n",
    "for i, col in enumerate(categorical_columns):\n",
    "    categories = ohe.categories_[i]\n",
    "    for category in categories:\n",
    "        feature_names.append(f\"{col}_{category}\")\n",
    "\n",
    "# Create a DataFrame for the encoded features\n",
    "X_categorical_encoded_df = pd.DataFrame(X_categorical_encoded, columns=feature_names)\n",
    "X_categorical_encoded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the numerical columns to be scaled\n",
    "numerical_columns = ['Year', 'Duration', 'Votes']\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the selected numerical columns\n",
    "X_numeric_scaled = scaler.fit_transform(X[numerical_columns])\n",
    "\n",
    "# Create a DataFrame for the scaled features\n",
    "X_numeric_scaled_df = pd.DataFrame(X_numeric_scaled, columns=numerical_columns)\n",
    "X_numeric_scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the scaled columns and onehotencoded columns\n",
    "X_final = pd.concat([X_numeric_scaled_df, X_categorical_encoded_df, ], axis=1)\n",
    "X_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Reshape 'Rating' to a 2D array for StandardScaler\n",
    "y_scaled = scaler.fit_transform(df['Rating'].values.reshape(-1, 1))\n",
    "\n",
    "# Convert 'y_scaled' back to a DataFrame\n",
    "y = pd.DataFrame(y_scaled, columns=['Rating'])\n",
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing data \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "# Create a Linear Regression model\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "# Fit the model on the training data\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_test = lr_model.predict(X_test)\n",
    "y_pred_train = lr_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "\n",
    "print(f\"Test Mean Squared Error : {mse_test}\")\n",
    "print(f\"Test R-squared (R^2) Score: {r2_test}\")\n",
    "\n",
    "print(f\"Train Mean Squared Error : {mse_train}\")\n",
    "print(f\"Train R-squared (R^2) Score: {r2_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot for the test data\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_pred_test, alpha=0.5, color='blue', label='Actual vs Predicted (Test Data)')\n",
    "plt.title('Actual vs Predicted Values')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Random Forest Regressor model\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_test = rf_model.predict(X_test)\n",
    "y_pred_train = rf_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "\n",
    "print(\"Random Forest Regressor Model Evaluation:\")\n",
    "print(f\"Test Mean Squared Error: {mse_test}\")\n",
    "print(f\"Test R-squared (R^2) Score: {r2_test}\")\n",
    "print(f\"Train Mean Squared Error: {mse_train}\")\n",
    "print(f\"Train R-squared (R^2) Score: {r2_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Gradient Boosting Regressor model\n",
    "gb_model = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_test = gb_model.predict(X_test)\n",
    "y_pred_train = gb_model.predict(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "\n",
    "print(\"Gradient Boosting Regressor Model Evaluation:\")\n",
    "print(f\"Test Mean Squared Error: {mse_test}\")\n",
    "print(f\"Test R-squared (R^2) Score: {r2_test}\")\n",
    "print(f\"Train Mean Squared Error: {mse_train}\")\n",
    "print(f\"Train R-squared (R^2) Score: {r2_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 20, 50],\n",
    "    'max_depth': [None, 3, 10, 20],\n",
    "    'min_samples_split': [1, 3, 5],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt']\n",
    "}\n",
    "\n",
    "\n",
    "# Create a Random Forest Regressor model\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(rf_model, param_grid, cv=5, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Get the best model\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_test = best_rf_model.predict(X_test)\n",
    "y_pred_train = best_rf_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "# Evaluate the model on the training data\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "\n",
    "print(\"Tuned Random Forest Regressor Model Evaluation (Test Data):\")\n",
    "print(f\"Test Mean Squared Error: {mse_test}\")\n",
    "print(f\"Test R-squared (R^2) Score: {r2_test}\")\n",
    "\n",
    "print(\"Tuned Random Forest Regressor Model Evaluation (Training Data):\")\n",
    "print(f\"Train Mean Squared Error: {mse_train}\")\n",
    "print(f\"Train R-squared (R^2) Score: {r2_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances from the best model\n",
    "feature_importances = best_rf_model.feature_importances_\n",
    "\n",
    "# Get the column names of your feature data \n",
    "feature_names = X_final.columns \n",
    "# Sort feature importances in descending order and get the top 10 features\n",
    "top_indices = np.argsort(feature_importances)[::-1][:10]\n",
    "top_features = [feature_names[i] for i in top_indices]\n",
    "top_importances = [feature_importances[i] for i in top_indices]\n",
    "\n",
    "# Create a bar plot to visualize feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(10), top_importances, align='center')\n",
    "plt.yticks(range(10), top_features)\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Top 10 Feature Importances')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
